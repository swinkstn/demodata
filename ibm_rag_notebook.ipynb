{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2aab3dbe",
   "metadata": {},
   "source": [
    "# üìì Mini RAG Notebook ‚Äî IBM Report Example\n",
    "This notebook demonstrates how to build a simple Retrieval-Augmented Generation (RAG) pipeline using an IBM report PDF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5afaa5",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6051396",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai faiss-cpu numpy requests pypdf tiktoken ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826756d3",
   "metadata": {},
   "source": [
    "## 2. Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e70ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import getpass\n",
    "\n",
    "# === Configuration ===\n",
    "PDF_URL = \"https://www.ibm.com/downloads/documents/us-en/1227c12d3a38b173\"  # IBM 2024 Annual Report\n",
    "CHAT_MODEL = \"cerebras/llama-3.3-70b\"        # choose: \"\"\n",
    "EMBED_MODEL = \"openai/text-embedding-ada-002\"  # or \"\"\n",
    "\n",
    "BASE_URL = \"https://ca-tor.ml.cloud.ibm.com/ml/gateway/v1\"  # or your custom endpoint\n",
    "API_KEY = getpass.getpass(\"Enter your API key: \")\n",
    "\n",
    "client = OpenAI(api_key=API_KEY, base_url=BASE_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b834d9",
   "metadata": {},
   "source": [
    "## 3. Download + Extract PDF Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beee132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "from pypdf import PdfReader\n",
    "\n",
    "pdf_path = Path(\"ibm_report.pdf\")\n",
    "if not pdf_path.exists():\n",
    "    print(\"Downloading PDF...\")\n",
    "    pdf_path.write_bytes(requests.get(PDF_URL).content)\n",
    "\n",
    "reader = PdfReader(str(pdf_path))\n",
    "text = \"\"\n",
    "for page in reader.pages:\n",
    "    if page.extract_text():\n",
    "        text += page.extract_text() + \"\\n\"\n",
    "\n",
    "print(\"Preview of text:\\n\", text[:800])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11249028",
   "metadata": {},
   "source": [
    "## 4. Chunking the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95b22bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def chunk_text(text, chunk_size=500, overlap=50):\n",
    "    encoder = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    tokens = encoder.encode(text)\n",
    "    chunks = []\n",
    "    for i in range(0, len(tokens), chunk_size - overlap):\n",
    "        chunk = tokens[i:i+chunk_size]\n",
    "        chunks.append(encoder.decode(chunk))\n",
    "    return chunks\n",
    "\n",
    "chunks = chunk_text(text, chunk_size=500, overlap=50)\n",
    "print(f\"Total chunks: {len(chunks)}\")\n",
    "print(\"Sample chunk:\\n\", chunks[0][:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6d8d46",
   "metadata": {},
   "source": [
    "## 5. Build FAISS Index with Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b63f38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "# Batch function\n",
    "def embed_chunks(chunks, batch_size=50):\n",
    "    all_embeddings = []\n",
    "    for i in range(0, len(chunks), batch_size):\n",
    "        batch = chunks[i:i+batch_size]\n",
    "        resp = client.embeddings.create(model=EMBED_MODEL, input=batch)\n",
    "        all_embeddings.extend([d.embedding for d in resp.data])\n",
    "    return np.array(all_embeddings, dtype=\"float32\")\n",
    "\n",
    "# Run embedding in batches\n",
    "embeddings = embed_chunks(chunks, batch_size=50)\n",
    "\n",
    "# Build FAISS index\n",
    "dim = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "index.add(embeddings)\n",
    "\n",
    "print(\"FAISS index ready with\", index.ntotal, \"vectors.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda4c80f",
   "metadata": {},
   "source": [
    "## 6. Retrieval Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527e4c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query, k=3):\n",
    "    q_emb = client.embeddings.create(model=EMBED_MODEL, input=query).data[0].embedding\n",
    "    D, I = index.search(np.array([q_emb]).astype(\"float32\"), k=k)\n",
    "    return [chunks[i] for i in I[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c423dd8d",
   "metadata": {},
   "source": [
    "## 7. Ask Function (Chat with RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49523b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(query, k=3):\n",
    "    retrieved = retrieve(query, k=k)\n",
    "    context = \"\\n\\n\".join(retrieved)\n",
    "    prompt = f\"Answer using the context below:\\n{context}\\n\\nUser question: {query}\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=CHAT_MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Example usage\n",
    "print(ask(\"What are IBM‚Äôs AI initiatives mentioned in this report?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f65d5a",
   "metadata": {},
   "source": [
    "## 8. Interactive Q&A (Buttons + Chatbox)\n",
    "\n",
    "You can now explore the IBM report in two ways:\n",
    "\n",
    "- üîò **Click a button** to run a predefined ‚Äústarter‚Äù question.  \n",
    "- üí¨ **Type your own question** into the chatbox below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebd03d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Predefined starter questions\n",
    "questions = [\n",
    "    \"What are IBM‚Äôs AI initiatives mentioned in this report?\",\n",
    "    \"What are IBM‚Äôs main strategic priorities for 2024?\",\n",
    "    \"What risks to growth does IBM identify?\",\n",
    "    \"What does the report say about sustainability?\",\n",
    "    \"Which industries are adopting AI according to the report?\"\n",
    "]\n",
    "\n",
    "output_box = widgets.Output()\n",
    "\n",
    "# Button click handler\n",
    "def on_button_click(b):\n",
    "    with output_box:\n",
    "        clear_output(wait=True)\n",
    "        print(f\"‚ùì {b.description}\\n\")\n",
    "        print(\"üí° Answer:\\n\")\n",
    "        print(ask(b.description))\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Create and display buttons\n",
    "button_box = widgets.VBox([\n",
    "    widgets.Button(description=q, layout=widgets.Layout(width=\"auto\"))\n",
    "    for q in questions\n",
    "])\n",
    "\n",
    "for btn in button_box.children:\n",
    "    btn.on_click(on_button_click)\n",
    "\n",
    "# Free-form input\n",
    "input_box = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Type your question here...',\n",
    "    description='Ask:',\n",
    "    layout=widgets.Layout(width=\"80%\")\n",
    ")\n",
    "\n",
    "def on_enter(change):\n",
    "    if change['name'] == 'value' and change['new']:\n",
    "        query = change['new']\n",
    "        with output_box:\n",
    "            print(f\"‚ùì {query}\\n\")\n",
    "            print(\"üí° Answer:\\n\")\n",
    "            print(ask(query))\n",
    "            print(\"-\" * 50)\n",
    "        input_box.value = \"\"  # clear input after submit\n",
    "\n",
    "input_box.observe(on_enter)\n",
    "\n",
    "# Display everything\n",
    "display(widgets.Label(\"üîπ Click a starter question:\"), button_box)\n",
    "display(widgets.Label(\"üîπ Or type your own:\"), input_box, output_box)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b418567b-6243-43f2-8155-f3f52f0af594",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rag_env)",
   "language": "python",
   "name": "rag_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
